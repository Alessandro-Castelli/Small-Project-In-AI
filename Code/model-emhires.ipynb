{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4166,"sourceType":"datasetVersion","datasetId":2489}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-24T15:14:51.741005Z","iopub.execute_input":"2024-02-24T15:14:51.741529Z","iopub.status.idle":"2024-02-24T15:14:51.752560Z","shell.execute_reply.started":"2024-02-24T15:14:51.741496Z","shell.execute_reply":"2024-02-24T15:14:51.751151Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"/kaggle/input/30-years-of-european-solar-generation/EMHIRESPV_TSh_CF_Country_19862015.csv\n/kaggle/input/30-years-of-european-solar-generation/emhirespv_gonzalezaparicioetal2017_newtemplate_corrected_last.pdf\n/kaggle/input/30-years-of-european-solar-generation/EMHIRES_PVGIS_TSh_CF_n2_19862015.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.compose import ColumnTransformer\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport seaborn as sns\nimport numpy as np\nimport math\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:14:51.754918Z","iopub.execute_input":"2024-02-24T15:14:51.755322Z","iopub.status.idle":"2024-02-24T15:14:51.766495Z","shell.execute_reply.started":"2024-02-24T15:14:51.755276Z","shell.execute_reply":"2024-02-24T15:14:51.765478Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/30-years-of-european-solar-generation/EMHIRESPV_TSh_CF_Country_19862015.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:14:51.767777Z","iopub.execute_input":"2024-02-24T15:14:51.768155Z","iopub.status.idle":"2024-02-24T15:14:53.305347Z","shell.execute_reply.started":"2024-02-24T15:14:51.768124Z","shell.execute_reply":"2024-02-24T15:14:53.304466Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Convert the string \"01/01/1986 00:00\" to a datetime object with the specified format\nstart_date = pd.to_datetime(\"01/01/1986 00:00\", format=\"%m/%d/%Y %H:%M\")\n\n# Create an array of integers from 0 to the length of df4\nhours = np.arange(len(df))\n\n# Add the array of hours to the start date and assign the result to a new column 'Date' in df4\ndf['Date'] = start_date + pd.to_timedelta(hours, unit='h')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:14:53.306642Z","iopub.execute_input":"2024-02-24T15:14:53.307440Z","iopub.status.idle":"2024-02-24T15:14:53.337622Z","shell.execute_reply.started":"2024-02-24T15:14:53.307407Z","shell.execute_reply":"2024-02-24T15:14:53.336388Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df = df.dropna() # Removes rows with null values","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:14:53.340584Z","iopub.execute_input":"2024-02-24T15:14:53.340940Z","iopub.status.idle":"2024-02-24T15:14:53.372694Z","shell.execute_reply.started":"2024-02-24T15:14:53.340912Z","shell.execute_reply":"2024-02-24T15:14:53.371450Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Use the melt method to combine the state columns into a single \"Countries\" column\ndf = pd.melt(df, id_vars=['Date'], value_vars=['AT', 'BE','BG','CH','CY','CZ','DE','DK','EE','ES','FI','FR','EL','HR','HU','IE','IT','LT','LU','LV','NL','NO','PL','PT' ,'RO', 'SI', 'SK', 'SE', 'UK'], var_name='COUNTRY', value_name='ValueEmhires')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:14:53.373925Z","iopub.execute_input":"2024-02-24T15:14:53.374628Z","iopub.status.idle":"2024-02-24T15:14:53.902566Z","shell.execute_reply.started":"2024-02-24T15:14:53.374598Z","shell.execute_reply":"2024-02-24T15:14:53.901308Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Convert 'Date' to datetime and extract features\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.month\ndf['Day'] = df['Date'].dt.day\ndf['Hour'] = df['Date'].dt.hour\n\n# Remove the original 'Date' column\ndf = df.drop(['Date'], axis=1)\n\ncountry_encoder = LabelEncoder()\ndf['COUNTRY'] = country_encoder.fit_transform(df['COUNTRY'])\n\n# Apply one-hot encoding to the 'COUNTRY' column\ndf = pd.get_dummies(df, columns=['COUNTRY'], prefix='country')\ndf = pd.get_dummies(df, columns=['Year'], prefix='year')\ndf = pd.get_dummies(df, columns=['Month'], prefix='month')\ndf = pd.get_dummies(df, columns=['Day'], prefix='day')\n\n\n# Convert boolean columns to numerical values (0 or 1).\nboolean_columns = [\n    'country_0', 'country_1', 'country_2', 'country_3', 'country_4', 'country_5',\n    'country_6', 'country_7', 'country_8', 'country_9', 'country_10', 'country_11',\n    'country_12', 'country_13', 'country_14', 'country_15', 'country_16', 'country_17',\n    'country_18', 'country_19', 'country_20', 'country_21', 'country_22', 'country_23',\n    'country_24', 'country_25', 'country_26', 'country_27', 'country_28',\n    'year_1986', 'year_1987', 'year_1988', 'year_1989', 'year_1990', 'year_1991',\n    'year_1992', 'year_1993', 'year_1994', 'year_1995', 'year_1996', 'year_1997',\n    'year_1998', 'year_1999', 'year_2000', 'year_2001', 'year_2002', 'year_2003',\n    'year_2004', 'year_2005', 'year_2006', 'year_2007', 'year_2008', 'year_2009',\n    'year_2010', 'year_2011', 'year_2012', 'year_2013', 'year_2014', 'year_2015',\n    'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12',\n    'day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6', 'day_7', 'day_8', 'day_9', 'day_10', 'day_11', 'day_12', 'day_13', 'day_14', 'day_15', 'day_16', 'day_17', 'day_18', 'day_19', 'day_20', 'day_21', 'day_22', 'day_23', 'day_24', 'day_25', 'day_26', 'day_27', 'day_28', 'day_29', 'day_30', 'day_31'\n]\n\n\ndf[boolean_columns] = df[boolean_columns].astype(int)\n\n\n# Print the resulting dataframe\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:14:53.903927Z","iopub.execute_input":"2024-02-24T15:14:53.904865Z","iopub.status.idle":"2024-02-24T15:15:09.409453Z","shell.execute_reply.started":"2024-02-24T15:14:53.904832Z","shell.execute_reply":"2024-02-24T15:15:09.408285Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"         ValueEmhires  Hour  country_0  country_1  country_2  country_3  \\\n0                 0.0     0          1          0          0          0   \n1                 0.0     1          1          0          0          0   \n2                 0.0     2          1          0          0          0   \n3                 0.0     3          1          0          0          0   \n4                 0.0     4          1          0          0          0   \n...               ...   ...        ...        ...        ...        ...   \n7626067           0.0    19          0          0          0          0   \n7626068           0.0    20          0          0          0          0   \n7626069           0.0    21          0          0          0          0   \n7626070           0.0    22          0          0          0          0   \n7626071           0.0    23          0          0          0          0   \n\n         country_4  country_5  country_6  country_7  ...  day_22  day_23  \\\n0                0          0          0          0  ...       0       0   \n1                0          0          0          0  ...       0       0   \n2                0          0          0          0  ...       0       0   \n3                0          0          0          0  ...       0       0   \n4                0          0          0          0  ...       0       0   \n...            ...        ...        ...        ...  ...     ...     ...   \n7626067          0          0          0          0  ...       0       0   \n7626068          0          0          0          0  ...       0       0   \n7626069          0          0          0          0  ...       0       0   \n7626070          0          0          0          0  ...       0       0   \n7626071          0          0          0          0  ...       0       0   \n\n         day_24  day_25  day_26  day_27  day_28  day_29  day_30  day_31  \n0             0       0       0       0       0       0       0       0  \n1             0       0       0       0       0       0       0       0  \n2             0       0       0       0       0       0       0       0  \n3             0       0       0       0       0       0       0       0  \n4             0       0       0       0       0       0       0       0  \n...         ...     ...     ...     ...     ...     ...     ...     ...  \n7626067       0       0       0       0       0       0       0       1  \n7626068       0       0       0       0       0       0       0       1  \n7626069       0       0       0       0       0       0       0       1  \n7626070       0       0       0       0       0       0       0       1  \n7626071       0       0       0       0       0       0       0       1  \n\n[7626072 rows x 104 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:15:09.411098Z","iopub.execute_input":"2024-02-24T15:15:09.412397Z","iopub.status.idle":"2024-02-24T15:15:09.428810Z","shell.execute_reply.started":"2024-02-24T15:15:09.412329Z","shell.execute_reply":"2024-02-24T15:15:09.427371Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7626072 entries, 0 to 7626071\nColumns: 104 entries, ValueEmhires to day_31\ndtypes: float64(1), int32(1), int64(102)\nmemory usage: 5.9 GB\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## wandb link: https://wandb.ai/ales-2000-09/EMHIRES?workspace=user-ales-2000-09","metadata":{}},{"cell_type":"code","source":"import wandb\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"Label\")\n\nwandb.login(key=secret_value_0)\n\nwandb.init(project='EMHIRES', save_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:15:09.430368Z","iopub.execute_input":"2024-02-24T15:15:09.430755Z","iopub.status.idle":"2024-02-24T15:15:45.169225Z","shell.execute_reply.started":"2024-02-24T15:15:09.430723Z","shell.execute_reply":"2024-02-24T15:15:45.168322Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33males-2000-09\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240224_151512-mzm3312n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ales-2000-09/EMHIRES/runs/mzm3312n' target=\"_blank\">young-cloud-34</a></strong> to <a href='https://wandb.ai/ales-2000-09/EMHIRES' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ales-2000-09/EMHIRES' target=\"_blank\">https://wandb.ai/ales-2000-09/EMHIRES</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ales-2000-09/EMHIRES/runs/mzm3312n' target=\"_blank\">https://wandb.ai/ales-2000-09/EMHIRES/runs/mzm3312n</a>"},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ales-2000-09/EMHIRES/runs/mzm3312n?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7975ccfdadd0>"},"metadata":{}}]},{"cell_type":"code","source":"# # Model definition\n# class LinearRegressionModel(nn.Module):\n#     def __init__(self, input_dim, output_dim):\n#         super(LinearRegressionModel, self).__init__()\n#         self.linear = nn.Linear(input_dim, output_dim)\n\n#     def forward(self, x):\n#         out = self.linear(x)\n#         return out","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:15:45.174002Z","iopub.execute_input":"2024-02-24T15:15:45.174448Z","iopub.status.idle":"2024-02-24T15:15:46.061042Z","shell.execute_reply.started":"2024-02-24T15:15:45.174413Z","shell.execute_reply":"2024-02-24T15:15:46.059893Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# class RegressionModel(nn.Module):\n#     def __init__(self, input_dim, hidden_dim, output_dim):\n#         super(RegressionModel, self).__init__()\n#         self.layer1 = nn.Linear(input_dim, hidden_dim)\n#         self.relu = nn.ReLU()\n#         self.layer2 = nn.Linear(hidden_dim, output_dim)\n\n#     def forward(self, x):\n#         out = self.layer1(x)\n#         out = self.relu(out)\n#         out = self.layer2(out)\n#         return out\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:15:46.064880Z","iopub.execute_input":"2024-02-24T15:15:46.065405Z","iopub.status.idle":"2024-02-24T15:15:47.193606Z","shell.execute_reply.started":"2024-02-24T15:15:46.065365Z","shell.execute_reply":"2024-02-24T15:15:47.192415Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# class RegressionModel(nn.Module):\n#     def __init__(self, input_dim, hidden_dim, output_dim):\n#         super(RegressionModel, self).__init__()\n#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n#         self.relu1 = nn.ReLU()\n#         self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n#         self.relu2 = nn.ReLU()\n#         self.fc3 = nn.Linear(hidden_dim, output_dim)\n\n#     def forward(self, x):\n#         out = self.fc1(x)\n#         out = self.relu1(out)\n#         out = self.fc2(out)\n#         out = self.relu2(out)\n#         out = self.fc3(out)\n#         return out\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:15:47.194930Z","iopub.execute_input":"2024-02-24T15:15:47.196234Z","iopub.status.idle":"2024-02-24T15:15:48.110255Z","shell.execute_reply.started":"2024-02-24T15:15:47.196196Z","shell.execute_reply":"2024-02-24T15:15:48.108934Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"class RNNRegressionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(RNNRegressionModel, self).__init__()\n        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        out, _ = self.rnn(x)\n        if len(out.shape) > 2:\n            out = self.fc(out[:, -1, :])\n        else:\n            out = self.fc(out)\n        return out.squeeze(1) if len(out.shape) > 2 else out","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:15:48.111770Z","iopub.execute_input":"2024-02-24T15:15:48.112914Z","iopub.status.idle":"2024-02-24T15:15:49.036659Z","shell.execute_reply.started":"2024-02-24T15:15:48.112873Z","shell.execute_reply":"2024-02-24T15:15:49.035810Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Identify the 'ValueEmhires' columntarget_column = 'ValueEmhires'\ntarget_index = df.columns.get_loc('ValueEmhires')\n\n# Select all columns except 'ValueEmhires' as input\nX = df.iloc[:, target_index+1:]\n\n# Select only 'ValueEmhires' as the target\ny = df['ValueEmhires']\n\nprint(X)\nprint(y)\n# Split the dataset into training, validation, and test sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n# Number of input and output features\ninput_dim = X_train.shape[1]\noutput_dim = 1\n\n# Initialize the model\n#model = LinearRegressionModel(input_dim, output_dim)\n\n# # Default Initialization\n# nn.init.xavier_uniform_(model.linear.weight)\n# nn.init.zeros_(model.linear.bias)\n\n#model = RegressionModel(input_dim, input_dim*2, output_dim)\nprint(input_dim)\nmodel = RNNRegressionModel(input_dim, input_dim*2, output_dim)\n\n\n# Define the loss function and optimizer\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.00001)\n\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:15:49.041245Z","iopub.execute_input":"2024-02-24T15:15:49.042138Z","iopub.status.idle":"2024-02-24T15:16:19.587423Z","shell.execute_reply.started":"2024-02-24T15:15:49.042096Z","shell.execute_reply":"2024-02-24T15:16:19.585808Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"         Hour  country_0  country_1  country_2  country_3  country_4  \\\n0           0          1          0          0          0          0   \n1           1          1          0          0          0          0   \n2           2          1          0          0          0          0   \n3           3          1          0          0          0          0   \n4           4          1          0          0          0          0   \n...       ...        ...        ...        ...        ...        ...   \n7626067    19          0          0          0          0          0   \n7626068    20          0          0          0          0          0   \n7626069    21          0          0          0          0          0   \n7626070    22          0          0          0          0          0   \n7626071    23          0          0          0          0          0   \n\n         country_5  country_6  country_7  country_8  ...  day_22  day_23  \\\n0                0          0          0          0  ...       0       0   \n1                0          0          0          0  ...       0       0   \n2                0          0          0          0  ...       0       0   \n3                0          0          0          0  ...       0       0   \n4                0          0          0          0  ...       0       0   \n...            ...        ...        ...        ...  ...     ...     ...   \n7626067          0          0          0          0  ...       0       0   \n7626068          0          0          0          0  ...       0       0   \n7626069          0          0          0          0  ...       0       0   \n7626070          0          0          0          0  ...       0       0   \n7626071          0          0          0          0  ...       0       0   \n\n         day_24  day_25  day_26  day_27  day_28  day_29  day_30  day_31  \n0             0       0       0       0       0       0       0       0  \n1             0       0       0       0       0       0       0       0  \n2             0       0       0       0       0       0       0       0  \n3             0       0       0       0       0       0       0       0  \n4             0       0       0       0       0       0       0       0  \n...         ...     ...     ...     ...     ...     ...     ...     ...  \n7626067       0       0       0       0       0       0       0       1  \n7626068       0       0       0       0       0       0       0       1  \n7626069       0       0       0       0       0       0       0       1  \n7626070       0       0       0       0       0       0       0       1  \n7626071       0       0       0       0       0       0       0       1  \n\n[7626072 rows x 103 columns]\n0          0.0\n1          0.0\n2          0.0\n3          0.0\n4          0.0\n          ... \n7626067    0.0\n7626068    0.0\n7626069    0.0\n7626070    0.0\n7626071    0.0\nName: ValueEmhires, Length: 7626072, dtype: float64\n103\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7626072 entries, 0 to 7626071\nColumns: 104 entries, ValueEmhires to day_31\ndtypes: float64(1), int32(1), int64(102)\nmemory usage: 5.9 GB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:16:19.588616Z","iopub.execute_input":"2024-02-24T15:16:19.588929Z","iopub.status.idle":"2024-02-24T15:16:20.528732Z","shell.execute_reply.started":"2024-02-24T15:16:19.588905Z","shell.execute_reply":"2024-02-24T15:16:20.526887Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7626072 entries, 0 to 7626071\nColumns: 104 entries, ValueEmhires to day_31\ndtypes: float64(1), int32(1), int64(102)\nmemory usage: 5.9 GB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training\nepochs = 2\nbatch_size = 5000\nwandb.log({'Epoch': epochs})\nwandb.log({'batch_size': batch_size})\n\nfor epoch in range(epochs):\n    model.train()\n    for i in range(0, X_train.shape[0], batch_size):\n        inputs = torch.from_numpy(X_train.iloc[i:i+batch_size].values).float()\n        labels = torch.from_numpy(y_train.iloc[i:i+batch_size].values).float().unsqueeze(1)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    # Validation\n    model.eval()\n    val_loss_total = 0.0\n\n    with torch.no_grad():\n        for i in range(0, X_val.shape[0], batch_size):\n            val_batch_inputs = torch.from_numpy(X_val.iloc[i:i+batch_size].values).float()\n            val_batch_labels = torch.from_numpy(y_val.iloc[i:i+batch_size].values).float().unsqueeze(1)\n\n            val_outputs = model(val_batch_inputs)\n            val_loss = criterion(val_outputs, val_batch_labels)\n            val_loss_total += val_loss.item()\n\n    avg_val_loss = val_loss_total / (X_val.shape[0] / batch_size)\n\n    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {loss.item()}, Validation Loss: {avg_val_loss}')\n    wandb.log({'Training Loss': loss.item(), 'Validation Loss': avg_val_loss})\n\n\n# Test\nmodel.eval()\nwith torch.no_grad():\n    test_inputs = torch.from_numpy(X_test.values).float()\n    test_labels = torch.from_numpy(y_test.values).float().unsqueeze(1)\n    test_outputs = model(test_inputs)\n    test_loss = criterion(test_outputs, test_labels)\n\nprint(f'Test Loss: {test_loss.item()}')\nwandb.log({'Test Loss': test_loss.item()})\n\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:16:20.530227Z","iopub.execute_input":"2024-02-24T15:16:20.530626Z","iopub.status.idle":"2024-02-24T15:46:24.130551Z","shell.execute_reply.started":"2024-02-24T15:16:20.530594Z","shell.execute_reply":"2024-02-24T15:46:24.129450Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/2, Training Loss: 0.04110394045710564, Validation Loss: 0.04230914172925139\nEpoch 2/2, Training Loss: 0.03785869851708412, Validation Loss: 0.03948716109068664\nTest Loss: 0.03929314762353897\n","output_type":"stream"},{"name":"stderr","text":"wandb: WARNING No program path found when generating artifact job source for a non-colab notebook run. See https://docs.wandb.ai/guides/launch/create-job\nwandb: WARNING Source type is set to 'artifact' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.231 MB of 0.231 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Training Loss</td><td>█▁</td></tr><tr><td>Validation Loss</td><td>█▁</td></tr><tr><td>batch_size</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>2</td></tr><tr><td>Test Loss</td><td>0.03929</td></tr><tr><td>Training Loss</td><td>0.03786</td></tr><tr><td>Validation Loss</td><td>0.03949</td></tr><tr><td>batch_size</td><td>5000</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">young-cloud-34</strong> at: <a href='https://wandb.ai/ales-2000-09/EMHIRES/runs/mzm3312n' target=\"_blank\">https://wandb.ai/ales-2000-09/EMHIRES/runs/mzm3312n</a><br/>Synced 6 W&B file(s), 0 media file(s), 9 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240224_151512-mzm3312n/logs</code>"},"metadata":{}}]}]}